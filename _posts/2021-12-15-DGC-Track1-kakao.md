---
layout: posts
title: 2021 데이터그랜드 컨퍼런스 '카카오 추천팀 - 우리 생활 속 추천 시스템'
categories: ['interest']
tags: [performance-marketing]
---

우리 생활 속 추천 시스템, 어떻게 발전해 왔고, 어떻게 발전해 나가고 있는가? by 카카오 추천팀
========

- 추천 기술이 어떻게 발전해왔는지
- 추천 기술은 어디로 발전해 나가고 있는지


추천 시스템이 푸는 문제
----
아이스크림 종류가 100개인 아이스크림 가게가 있다.   
이 가게에 온 A,B,C,D 고객은 이력 정보가 있을 수도 없을 수도 있다.   

||7일|8일|9일|10일|
|:---:|:---:|:---:|:---:|:---:|
|A|딸기|다크초코|민트초코|
|B|바닐라||오렌지||
|C||딸기||
|D|

이를 토대로 10일 A,B,C,D에게 어떤 아이스크림을 추천해야하나?


![화면 캡처 2021-12-31 122149](https://user-images.githubusercontent.com/86539195/147801302-b3a97bc8-a456-4288-a8fe-26e358297041.png)

간단하게 추천시스템을 정리해보면   
사용자 정보 & 사용 이력 정보 , 추천할 수 있는 아이템 리스트 & 아이템에 대한 정보를 넣고   
"뭐 추천할까?" 라는 함수를 통해   
사용자가 좋아할만한 아이템 리스트를 추출한다.   

"추천 시스템은 **아이템**에 대한 **사용자**의 **선호도를 예측**하는 시스템"   

사용자 정보 & 사용 이력 정보, 특정 아이스크림 정보를 이용하여   
아이템에 대한 사용자의 예측 선호도를 알 수 있다.   

선호도 예측에 사용할 수 있는 알고리즘
- Collaborative Filtering
- Click Through Rate Prediction
- Sequential Recommendation


![화면 캡처 2021-12-31 125003](https://user-images.githubusercontent.com/86539195/147802230-75b29392-f286-486b-a4f7-17a9a07fca61.png)

"뭐 추천할까?" 함수를 완성해보면   
"좋아할까?" 라는 함수를 통해 모든 아이스크림에 대한 선호도를 예측하고   
가장 예측 선호도가 높은 아이스크림을 추천 결과로 선정하여 "정렬"한다.   


추천 시스템의 성과
----

추천 시스템 성능은 어떻게 측정할 수 있을까?   

추천 성능 기준 버전1: 단기 사용자 만족도
- 인당 클릭수: 사용자 하루 평균 클릭 수
- 체류시간: 사용자가 서비스에 머문 시간

아이스크림 가게 이야기를 다시보면 3개를 추천해줄 때   
예측 선호도 순으로 a에게 아몬드초코, 오레오초코, 초콜릿무스를 추천해준다고 하자   

이렇게 비슷한 것으로 추천해줘도 괜찮을까?

![화면 캡처 2021-12-31 130829](https://user-images.githubusercontent.com/86539195/147802749-0b5d835d-5276-4d9d-80fe-3da7e2ae9527.png)

70% 로맨스 영화를 소비하고 30% 액션 영화를 소비하는 특정 사용자의 사용 이력 데이터만 이용해서 추천하면   
추천 결과 100% 로맨스 영화만이 추천된다.   

Calibration 적용 시에는 70% 로맨스 영화, 30% 액션 영화가 추천되어 다양화(Diversification)가 가능하다.   

다양화에 사용할 수 있는 알고리즘
- Fuzzy deduping
- Sliding window
- Smooth Score Penalty
- Determinantal Point Processes(DPPs), Deep DPPs

하지만 다양화 로직을 적용하면 클릭률이 떨어지지 않을까?   

여러개를 보여주고 스크롤 가능한 상황이라면 다양화 로직을 적용했을 때   
아이템별 클릭률 ↓ / 스크롤 수 ↑ / 인당 클릭수 ↑   

피드백 루프(Feedback Loop)를 가지고 있다   
: 특정 시스템의 결과물 일부 혹은 전부가 미래의 학습 데이터로 사용되는 구조를 가질 경우
![화면 캡처 2021-12-31 131937](https://user-images.githubusercontent.com/86539195/147803101-a706ab1c-df59-4ebb-8578-ea627224c586.png)

> **Filter bubble**   
> 개인화 검색(혹은 추천)엔진이 유저의 과거 이력에 기반한 검색(혹은 추천)결과를 내보내면서 
> **유저가** 새로운  유형/견해의 콘텐츠에 노출되지 않고 **특정 유형/견해를 갖는 콘텐츠에 고립되는 것**

단기적으로 사용자들이 만족하더라도,   
소비 다양성이 줄어들면 서비스 이탈율은 높아질 것이다!   


추천 시스템은 어디로 발전해 나가는가?
-----

추천 시스템은 사용자의 **소비 다양성**을 높여서 **장기적인 서비스 만족도**를 높여야 한다.   

"**추천 플랫폼의 장기적인 목표**는, 사용자가 현재 원하는 것을 충족시켜주는 것 뿐만 아니라 **미래에** 그들이 
**더 자주 추천 플랫폼에 방문하도록 만드는 것**이다."

"페이스북에서 가장 중요하게 생각하는 가치는 사용자들에게 장기적인 가치(long-term value)를 주는 것"

> **User Exploration**   
> 사용자가 추천시스템에 **알려주지 않았던** 관심사를 **찾아내는 것**

추천 동작 방식 예시: 협업 필터링 (Collaboration Filtering)   

![화면 캡처 2021-12-31 134148](https://user-images.githubusercontent.com/86539195/147803756-5e24e28c-65b5-4a08-ac4e-dd02836ec607.png)

나와 비슷한 사람을 토대로 추천

![화면 캡처 2021-12-31 134249](https://user-images.githubusercontent.com/86539195/147803795-0d715f9c-4449-4efb-8101-3a97a64ff3df.png)

![화면 캡처 2021-12-31 134315](https://user-images.githubusercontent.com/86539195/147803806-9763ed81-d3ff-430f-8961-b9b8efc2eb08.png)

영역 밖에 있는 걸 찾아내자! 가 User Exploration

User Exploration 관련
- 목표 지표로는 Serendipity, Novelty 등 활용
- 특히, Serendipity는 장기적인 서비스 만족도와 상관관계가 있음도 확인됨
- 강화학습(Reinforcement Learning)분야에서 활발하게 연구되고 있는 Exploration Algorithm을 활용
- Entropy Reguiarization
- Intrinsic Motivation and Reward Shaping


정리
---

**추천 목표**는 단기 만족도 증가에서 장기 만족도 증가로 변화   
**작전**은 소비 다양성 늘리기 & 새로운 관심사 찾기

